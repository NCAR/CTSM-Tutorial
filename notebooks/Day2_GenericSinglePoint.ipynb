{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2b: Running a generic single-point case\n",
    "\n",
    "This tutorial is an introduction to running single-point simulations of the Community Terrestrial Systems Model (CTSM).  It will guide you through setting up the required driver data (i.e. surface and atmosphere data) as well as setting up and submitting a single-point CTSM case.\n",
    "\n",
    "In the previous tutorial, `Day1_GlobalCase`, we set up and ran a global CTSM case. Many of the steps required to run a single-point case are similar, with some changes and additional required steps which we will cover here.\n",
    "<br><br>\n",
    "\n",
    "### Questions about this tutorial? \n",
    "- Please post them on the [CTSM forum in the CESM Bulletin Board](https://bb.cgd.ucar.edu/cesm/forums/ctsm-clm-mosart-rtm.134/). Note that this resource will require you to register and log in so that you can be notified of responses to your inquiries. \n",
    "- You can also file issues on the [NCAR CTSM-Tutorial GitHub repository](https://github.com/NCAR/CTSM-Tutorial-2022).\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this tutorial\n",
    "\n",
    "The tutorial has several components. Below you will find steps to: \n",
    "1. Generate subset surface and atmosphere data files at a single latitude and longitude point.\n",
    "2. Set up and submit a single-point case.\n",
    "3. Basic visualization of single-point model history files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note This tutorial assumes that you've completed the previous tutorials!\n",
    "If you haven't downloaded CTSM from the github repository you need to go back to the `NEON_Simulation_Tutorial` and do this first. If you haven't completed the Day 1 tutorial (`Day1_GlobalCase`), go back and do this first.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 1. Subset global surface and atmosphere files </h1>\n",
    "\n",
    "CTSM uses a surface data file to read in important grid cell-level information like vegetation, crop, and glacier grid cell fractions, the fractional cover of each plant functional type (PFT), and soil characteristics.\n",
    "\n",
    "A global surface data file is located and read by default for global CTSM cases, depending on the chosen _component set_ and _resolution_. To run CTSM at a single point, we will need to supply a surface data file at a specified latitude and longitude.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Remember from Day 1 that a <b>component set</b>, or coloquially a \"compset\", specifies a configuration for your case, including the component models, time period of simulation, and physics options. The <b>resolution</b> defines the model resolution or grid.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Similarly, when running in _DATM mode_, that is when using a \"data atmosphere model\", with climate data (e.g. temperature, precipitation, solar radiation, etc.) driven by an input file, CTSM needs DATM files. We can also provide subset global DATM for single-point runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> It is not strictly required to provide CTSM/CIME with subset DATM data in order to run a single-point case, as CTSM can just use the global files. However, your runs will be much faster if you use subset climate data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1.1 Use <em>subset_data</em> to subset surface and DATM files</h2>\n",
    "\n",
    "We have created a python script, *subset_data*, which will subset default global surface and DATM files at a user-specified latitude and longitude.\n",
    "\n",
    "This script is located in the CTSM source code, in the `tools/site_and_regional` folder.\n",
    "\n",
    "Navigate here now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd tools/site_and_regional\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"images/ls_subset_data.png\" width=\"588\" height=\"118\" alt=\"Example output from an ls command in the correct folder\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use this python script you must have some required python packages installed. On NCAR machines (like Cheyenne), you can load the NCAR python library, _ncar pylib_, by running `module load python` and then `ncar_pylib`. For this tutorial, we...\n",
    "\n",
    "TODO: update this!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> On NCAR or other machines, you can also use your own python environment if you want. Required third-party python packages are <i>scipy</i>, <i>xarray</i>, and <i>numpy</i>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the built-in print help to see what options are available for the subset data script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "./subset_data --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of options, but for now we will just use a few:\n",
    "\n",
    "`point` : this tells the script to subset data at a single point  \n",
    "`--lat` : this tells the script which latitude to subset at (*must be between -90 and 90*)  \n",
    "`--lon` : this tells the script which longitude to subset at (*can be between 0 and 360 or -180 and 180*)  \n",
    "`--site` : optional, specifies a site name or tag  \n",
    "`--create-surface` : tells the script to subset surface data  \n",
    "`--create-datm` : tells the script to subset DATM data  \n",
    "`--datm-syr` and `--datm-eyr`: starting and ending years for the DATM data to subset (*must be between 1901 and 2014*)  \n",
    "`--create-user-mods` : tells the script to create a *user_mods* directory (see below)  \n",
    "`--outdir` : specifies the directory to place subset data and user mods directory in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the script with these options. You can pick your own latitude and longitude, or use our suggestion of 39.98 and 105.28 (i.e. the NCAR Mesa Lab!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "./subset_data point --lat 39.98 --lon 105.28 --site my_point --create-surface --create-datm --datm-syr 1990 --datm-eyr 2014 --create-user-mods --outdir ~/my_subset_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may take a bit of time to subset all the climate data, but you should get a success message when it is finished!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1.2 Check on the subset files </h2>\n",
    "\n",
    "Once the subsetting has successfully finished, lets navigate to the specified output directory to check on the files that we just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/my_subset_data\n",
    "ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
