{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2b: Running a generic single-point case\n",
    "\n",
    "This tutorial is an introduction to running single-point simulations of the Community Terrestrial Systems Model (CTSM).  It will guide you through setting up the required driver data (i.e. surface and atmosphere data) as well as setting up and submitting a single-point CTSM case.\n",
    "\n",
    "In the previous tutorial, `Day1_GlobalCase`, we set up and ran a global CTSM case. Many of the steps required to run a single-point case are similar, with some changes and additional required steps which we will cover here.\n",
    "<br><br>\n",
    "\n",
    "### Questions about this tutorial? \n",
    "- Please post them on the [CTSM forum in the CESM Bulletin Board](https://bb.cgd.ucar.edu/cesm/forums/ctsm-clm-mosart-rtm.134/). Note that this resource will require you to register and log in so that you can be notified of responses to your inquiries. \n",
    "- You can also file issues on the [NCAR CTSM-Tutorial GitHub repository](https://github.com/NCAR/CTSM-Tutorial-2022).\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this tutorial\n",
    "\n",
    "The tutorial has several components. Below you will find steps to: \n",
    "1. Generate subset surface and atmosphere data files at a single latitude and longitude point.\n",
    "2. Set up and submit a single-point case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note This tutorial assumes that you've completed the previous tutorials!\n",
    "If you haven't downloaded CTSM from the github repository you need to go back to the `NEON_Simulation_Tutorial` and do this first. If you haven't completed the Day 1 tutorial (`Day1_GlobalCase`), go back and do this first.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 1. Subset global surface and atmosphere files </h1>\n",
    "\n",
    "CTSM uses a surface data file to read in important grid cell-level information like vegetation, crop, and glacier grid cell fractions, the fractional cover of each plant functional type (PFT), and soil characteristics.\n",
    "\n",
    "A global surface data file is located and read by default for global CTSM cases, depending on the chosen _component set_ and _resolution_. To run CTSM at a single point, we will need to supply a surface data file at a specified latitude and longitude.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Remember from Day 1 that a <b>component set</b>, or coloquially a \"compset\", specifies a configuration for your case, including the component models, time period of simulation, and physics options. The <b>resolution</b> defines the model resolution or grid.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Similarly, when running in _DATM mode_, that is when using a \"data atmosphere model\", with climate data (e.g. temperature, precipitation, solar radiation, etc.) driven by an input file, CTSM needs DATM files. We can also provide subset global DATM for single-point runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> It is not strictly required to provide CTSM/CIME with subset DATM data in order to run a single-point case, as CTSM can just use the global files. However, your runs will be much faster if you use subset climate data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1.1 Use <em>subset_data</em> to subset surface and DATM files</h2>\n",
    "\n",
    "We have created a python script, *subset_data*, which will subset default global surface and DATM files at a user-specified latitude and longitude.\n",
    "\n",
    "This script is located in the CTSM source code, in the `tools/site_and_regional` folder.\n",
    "\n",
    "Navigate here now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd tools/site_and_regional\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"../images/ls_subset_data.png\" width=\"588\" height=\"118\" alt=\"Example output from an ls command in the correct folder\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use this python script you must have some required python packages installed. On NCAR machines (like Cheyenne), you can load the NCAR python library, _ncar pylib_, by running `module load python` and then `ncar_pylib`. For this tutorial, we...\n",
    "\n",
    "TODO: update this!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> On NCAR or other machines, you can also use your own python environment if you want. Required third-party python packages are <i>scipy</i>, <i>xarray</i>, and <i>numpy</i>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the built-in print help to see what options are available for the subset data script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "./subset_data --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of options, but for now we will just use a few:\n",
    "\n",
    "`point` : this tells the script to subset data at a single point  \n",
    "`--lat` : this tells the script which latitude to subset at (*must be between -90 and 90*)  \n",
    "`--lon` : this tells the script which longitude to subset at (*can be between 0 and 360 or -180 and 180*)  \n",
    "`--site` : optional, specifies a site name or tag  \n",
    "`--create-surface` : tells the script to subset surface data  \n",
    "`--create-datm` : tells the script to subset DATM data  \n",
    "`--datm-syr` and `--datm-eyr`: starting and ending years for the DATM data to subset (*must be between 1901 and 2014*)  \n",
    "`--create-user-mods` : tells the script to create a *user_mods* directory (see below)  \n",
    "`--outdir` : specifies the directory to place subset data and user mods directory in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the script with these options. You can pick your own latitude and longitude, or use our suggestion of 39.98 and 105.28 (i.e. the NCAR Mesa Lab!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "./subset_data point --lat 39.98 --lon 105.28 --site my_point --create-surface --create-datm --datm-syr 2004 --datm-eyr 2014 --create-user-mods --outdir ~/my_subset_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may take a bit of time to subset all the climate data, but you should get a success message when it is finished!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1.2 Check on the subset files </h2>\n",
    "\n",
    "Once the subsetting has successfully finished, let's navigate to the specified output directory to check on the files that we just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/my_subset_data\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"../images/ls_subset_folder.png\" width=\"588\" height=\"118\" alt=\"Example output from an ls command in the subset data folder.\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a surface data file (e.g. *surfdata_0.9x1.25 ... .nc*) and two folders: **datmdata** and **user_mods**. \n",
    "\n",
    "* **datmdata** houses the subset DATM files\n",
    "* **user_mods** is a directory created that houses several files we will use to set up our single-point case\n",
    "\n",
    "Let's navigate into the **user_mods** directory to check them out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd user_mods\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see three files: *shell_commands*, *user_nl_clm*, and *user_nl_datm_streams*.  \n",
    "\n",
    "The *shell_commands* file contains *xmlchange* commands required to set up a single point case at the specified latitude and longitude.\n",
    "\n",
    "Take a look at this file if you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat shell_commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`./xmlchange CLM_USRDAT_DIR` - this tells CIME the location of an argument *CLM_USRDAT_DIR* which we can use to specify the main directory of subset data files  \n",
    "\n",
    "`./xmlchange PTS_LON` and `./xmlchange PTS_LAT` - this tells CIME that we are running at a specified latitude and longitude  \n",
    "\n",
    "`./xmlchange MPILIB` - this specifies a specific MPI library to use required for single-point runs.  \n",
    " \n",
    "   \n",
    "If you remember from the Day 1 tutorial, *user_nl_clm* is a Fortran namelist file used to set up different namelist options for CLM. Here, we are using it to specify the location of our subset surface data. Note the use of the variable `$CLM_USRDAT_DIR` set up in the *shell_commands* file.\n",
    "  \n",
    "    \n",
    "Similarly, *user_nl_datm_streams* specifies the location and a few other options for our subset DATM data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this **user_mods** directory when we create our single-point case (see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Notice:</b> If for whatever reason you end up moving the subset data directory (i.e. here <b>~/my_subset_data</b>), you will need to modify the xmlchange command that specifies the <i>CLM_USRDAT_DIR</i> to be the full path to the directory's new location. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 2. Create a single-point CTSM case </h1>\n",
    "\n",
    "Now that we have our subset data ready to go, we can set up our single-point case with CIME.\n",
    "\n",
    "The steps required here are very similar to the global case that we set up in the Day 1 tutorial, with a few differences. Mainly, we are going to specify a `--user-mods-dir` in our `./create_newcase` command as the full path to the **user_mods** folder we just created with *subset_data*. We will also choose a different component set and resolution.\n",
    "\n",
    "<h2> 2.1. Create the case </h2>\n",
    "\n",
    "As in our Day 1 Tutorial, we will navigate into the CTSM **scripts** directory to run the `create_newcase` script. Today we are going to be running a CLM-BGC simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd cime/scripts\n",
    "./create_newcase --case ~/clm_tutorial_cases/I2000_CTSM_singlept --res CLM_USRDAT --compset I2000Clm50BgcCrop --run-unsupported --user-mods-dirs ~/my_subset_data/user_mods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command should look fairly familiar to you, with some updated values and arguments.\n",
    "\n",
    "`--res` - defines the model resolution, or grid:\n",
    "* we are now using `CLM_USRDAT`, which should be used when we have user-specified domain (i.e. a subset surface data)\n",
    "\n",
    "`--compset` - defines the component set for the case:\n",
    "* `I2000Clm50BgcCrop` is an alias that describes using year 2000 initialization time, data-driven atmosphere (GSWP3v1 data), CLM 5.0 BGC with prognostic crop, along with some other component settings.\n",
    "\n",
    "`--user-mods-dirs` - this is where we tell CIME where our **user mods** directory is.\n",
    "* it should be the path to the directory that was created during our *subset_data* scripting\n",
    "* the namelist files (i.e. *user_nl_clm* and *user_nl_datm_streams*) will be copied into the case directory, and the commands within *shell_commands* will be executed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2.2. Set up the case and build the executable </h2>\n",
    "\n",
    "As with our global case, we will change into our case directory, set up our case (`./case.setup`) and then build the executable (`./case.build`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/clm_tutorial_cases/I2000_CTSM_singlept\n",
    "./case.setup\n",
    "./case.build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2.3. Customize the case </h2>\n",
    "\n",
    "As in our global case, we will invoke a few XML commands to update some runtime values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "./xmlchange STOP_OPTION=nyears\n",
    "./xmlchange STOP_N=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2.4. Submit the case </h2>\n",
    "\n",
    "Finally, let's submit the case as we did in Day 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "./case.submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a confirmation that it successfully submitted.\n",
    "\n",
    "### Congratulations! You've created and submtted a single-point CLM case!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
